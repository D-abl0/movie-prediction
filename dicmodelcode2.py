# -*- coding: utf-8 -*-
"""dicmodelcode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ouVFfZKWwavh7TK1eFk9F2XfikFGJ6A4
"""



import pandas as pd
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt')

dataset_path = 'movies.csv'

df = pd.read_csv(dataset_path)

df.describe()

"""# DATA CLEANING AND PRE PROCESSING"""

# Number of rows and columns in the original raw dataset

num_rows, num_columns = df.shape


print("Number of rows:", num_rows)
print("Number of columns:", num_columns)

# Dataset cleanning method - 1
# Removing duplicate values

df = df.drop_duplicates()

df.head()

# Number of rows and columns after dropping duplicate values
num_rows, num_columns = df.shape


print("Number of rows:", num_rows)
print("Number of columns:", num_columns)

column_data_types = df.dtypes

# Display the data type of each column
print("Data type of each column:")
print(column_data_types)



num_rows, num_columns = df.shape


print("Number of rows:", num_rows)
print("Number of columns:", num_columns)

# DATA CLEANNIG PROCESS - 2
# CONVERTING ALL THE VARIOUS TYPES OF DATA INTO A SINGLE TYPE

df['VOTES'] = df['VOTES'].str.replace(',', '').astype(float)

column_data_types = df.dtypes

# Display the data type of each column
print("Data type of each column:")
print(column_data_types)

df['YEAR'] = df['YEAR'].str.extract(r'(\d{4})').astype(float)

# Data cleaning process - 3
# removing null values

# We find the number of columns with the common null values and remove them to not skew the data instead of filling it up all three values
# with some filler.

nan_counts = df.isna().sum()


print("Number of NaN values per column:")
print(nan_counts)

columns_with_missing = ['RATING', 'VOTES', 'RunTime']
# 'YEAR', 'GENRE',

# Filtering the rows with missing values for any of the specified columns
rows_to_drop = df[df[columns_with_missing].isnull().all(axis=1)]


num_rows_missing = len(rows_to_drop)
print(f"Number of rows with missing values for specified columns: {num_rows_missing}")

df = df.drop(rows_to_drop.index)

num_rows_missing = len(rows_to_drop)

nan_counts = df.isna().sum()


print("Number of NaN values per column:")
print(nan_counts)

num_rows, num_columns = df.shape


print("Number of rows:", num_rows)
print("Number of columns:", num_columns)

# Data cleaning process - 4
# Filling in the data with other measures

# if we wanted to drop the rows with null values we are losing the majority of the rows so we are filling the
# null values with the median value of the entire column

df = df.dropna(subset=['GENRE'])

df['RATING'].fillna(df['RATING'].median(), inplace=True)
df['VOTES'].fillna(df['VOTES'].mean(), inplace=True)
df['RunTime'].fillna(df['RunTime'].median(), inplace=True)

df.head()

# Data cleaning method - 5
# Setting all the numeric characters to the same precision to avoid inconsistency

desired_precision = 2

pd.set_option('display.float_format', lambda x: f'{x:.{desired_precision}f}')

df.head()

# Data cleaning method - 6

# Converting all text data into lowercase data.

df['MOVIES'] = df['MOVIES'].str.lower()
df['GENRE'] = df['GENRE'].str.lower()
df['ONE-LINE'] = df['ONE-LINE'].str.lower()
df['STARS'] = df['STARS'].str.lower()

df.head()

num_rows, num_columns = df.shape


print("Number of rows:", num_rows)
print("Number of columns:", num_columns)

# Number of rows and columns left after removing outliers using the inter quartile range

num_rows, num_columns = df.shape


print("Number of rows:", num_rows)
print("Number of columns:", num_columns)

# data cleaning process - 8
# Removing the trailing whitespaces in the text data to avoid and inconsistencies.

df['MOVIES'] = df['MOVIES'].str.strip()
df['GENRE'] = df['GENRE'].str.strip()
df['ONE-LINE'] = df['ONE-LINE'].str.strip()
df['STARS'] = df['STARS'].str.strip()

df.head()

# Data cleaning and pre processing - 9
# removing the punctuation and special charaters

import re

def remove_special_characters(text):
    return re.sub(r'[^a-zA-Z0-9\s]', '', text)

df['MOVIES'] = df['MOVIES'].apply(remove_special_characters)
df['GENRE'] = df['GENRE'].apply(remove_special_characters)
df['ONE-LINE'] = df['ONE-LINE'].apply(remove_special_characters)
df['STARS'] = df['STARS'].apply(remove_special_characters)

df.head()

# Data cleaning process - 10
# Removing numbers from our text data columns

df['MOVIES'] = df['MOVIES'].apply(lambda x: re.sub(r'\d+', '', x))
df['GENRE'] = df['GENRE'].apply(lambda x: re.sub(r'\d+', '', x))
df['ONE-LINE'] = df['ONE-LINE'].apply(lambda x: re.sub(r'\d+', '', x))
df['STARS'] = df['STARS'].apply(lambda x: re.sub(r'\d+', '', x))

df.head()

# DATA CLEANING METHOD - 11
# Removing the extra white spaces for consistency

df['MOVIES'] = df['MOVIES'].apply(lambda x: ' '.join(x.split()))
df['GENRE'] = df['GENRE'].apply(lambda x: ' '.join(x.split()))
df['ONE-LINE'] = df['ONE-LINE'].apply(lambda x: ' '.join(x.split()))
df['STARS'] = df['STARS'].apply(lambda x: ' '.join(x.split()))
df.head()

# DATA CLEANING METHODS - 12
# REMOVING EMOTICONS AND EMOJIS TO AVOID DATA INTERRUPTION

def remove_emojis(text):
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"  # emoticons
                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                               u"\U0001F680-\U0001F6FF"  # transport & map symbols
                               u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)



df['MOVIES'] = df['MOVIES'].apply(remove_emojis)
df['GENRE'] = df['GENRE'].apply(remove_emojis)
df['ONE-LINE'] = df['ONE-LINE'].apply(remove_emojis)
df['STARS'] = df['STARS'].apply(remove_emojis)

df.head()

# Data cleaning method - 13
# expanding the contractions to avoid data inconsistencies



import contractions

df['MOVIES'] = df['MOVIES'].apply(contractions.fix)
df['GENRE'] = df['GENRE'].apply(contractions.fix)
df['ONE-LINE'] = df['ONE-LINE'].apply(contractions.fix)
df['STARS'] = df['STARS'].apply(contractions.fix)


df.head()

# Data cleaning process - 14
# Breaking the words into individual values else called tokenization but manually

df['GENRE'] = df['GENRE'].str.split()

print(df['GENRE'])



df.head()

"""### Splitting of the data into test, train and split and also using the RANDOM Forest Classifier on the data"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.ensemble import RandomForestClassifier


#converting the genre from list to a string joined by a ','
df['GENRE'] = df['GENRE'].apply(lambda x: ','.join(x) if isinstance(x, list) else x)



# Function to map ratings to classes based on new criteria for which we base our classification upon.
def map_ratings_to_classes(rating):
    if rating <= 6:
        return 'Flop'
    elif rating <= 7.5:
      return 'Average'
    else:
        return 'Hit'

df2 = df.copy()

df['RATING'] =  np.floor(df['RATING']).astype(int)

df['RATING'] = df['RATING'].apply(map_ratings_to_classes)


X = df.drop('RATING', axis=1)
y = df['RATING']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

numeric_features = ['VOTES', 'RunTime', 'YEAR']
categorical_features = ['GENRE','ONE-LINE','STARS']

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

rf_classifier_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))])


rf_classifier_pipeline.fit(X_train, y_train)


y_pred = rf_classifier_pipeline.predict(X_test)


print('Random Forest Classifier Evaluation:')
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')
print(confusion_matrix(y_test, y_pred, labels=['Flop','Average', 'Hit']))

print('Classification Report:')
print(classification_report(y_test, y_pred, target_names=['Flop','Average', 'Hit']))


conf_matrix = confusion_matrix(y_test, y_pred, labels=['Flop','Average', 'Hit'])
plt.figure(figsize=(10,7))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap='Blues', xticklabels=['Flop','Average', 'Hit'], yticklabels=['Flop','Average', 'Hit'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

df_vis = df.dropna(subset=['RunTime', 'RATING'])

plt.figure(figsize=(12, 6))
sns.boxplot(x='RATING', y='RunTime', data=df_vis)
plt.title('Distribution of Movie RunTimes by Rating Category')
plt.xlabel('Rating Category')
plt.ylabel('RunTime (Minutes)')
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'random_forest_classifier.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(rf_classifier_pipeline, file)

"""## Decision Tree Classifier on the data."""

from sklearn.tree import DecisionTreeClassifier, plot_tree

dt_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                              ('classifier', DecisionTreeClassifier(random_state=42))])

dt_pipeline.fit(X_train, y_train)
y_pred_dt = dt_pipeline.predict(X_test)


print(f'Accuracy: {accuracy_score(y_test, y_pred_dt)}')
print(confusion_matrix(y_test, y_pred))

print('Decision Tree Classifier Metrics:')
print(classification_report(y_test, y_pred_dt))

print(f'Accuracy: {accuracy_score(y_test, y_pred_dt)}')


conf_matrix_dt = confusion_matrix(y_test, y_pred_dt, labels=['Flop', 'Average', 'Hit'])
print(conf_matrix_dt)


plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix_dt, annot=True, fmt="d", cmap='Blues', xticklabels=['Flop', 'Average', 'Hit'], yticklabels=['Flop', 'Average', 'Hit'])
plt.title('Confusion Matrix for Decision Tree Classifier')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()


plt.figure(figsize=(20, 10))
plot_tree(dt_pipeline.named_steps['classifier'], max_depth=3, filled=True, class_names=['Flop', 'Average', 'Hit'], fontsize=10)
plt.title('Decision Tree Structure (Partial View)')
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'decision_tree_classifier.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(dt_pipeline, file)

"""## Gradient Boosting Classifier model on the data ."""

from sklearn.ensemble import GradientBoostingClassifier

gb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                              ('classifier', GradientBoostingClassifier(random_state=42))])

gb_pipeline.fit(X_train, y_train)
y_pred_gb = gb_pipeline.predict(X_test)


print('Gradient Boosting Classifier Metrics:')
print(classification_report(y_test, y_pred_gb))

print(f'Accuracy: {accuracy_score(y_test, y_pred_gb)}')


conf_matrix_gb = confusion_matrix(y_test, y_pred_gb, labels=['Flop', 'Average', 'Hit'])
print(conf_matrix_gb)


plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix_gb, annot=True, fmt="d", cmap='Blues', xticklabels=['Flop', 'Average', 'Hit'], yticklabels=['Flop', 'Average', 'Hit'])
plt.title('Confusion Matrix for Gradient Boosting Classifier')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

y_pred_prob_gb = gb_pipeline.predict_proba(X_test)


prob_df = pd.DataFrame(y_pred_prob_gb, columns=gb_pipeline.named_steps['classifier'].classes_)


prob_df_melted = prob_df.melt(var_name='Class', value_name='Probability')

plt.figure(figsize=(12, 6))
sns.violinplot(x='Class', y='Probability', data=prob_df_melted)
plt.title('Distribution of Predicted Probabilities by Class for Gradient Boosting Classifier')
plt.xlabel('Class')
plt.ylabel('Predicted Probability')
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'gradient_booster_classifier.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(gb_pipeline, file)

"""## Performing the basic logistic regression on the data."""

from sklearn.linear_model import LogisticRegression



logistic_regression_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(random_state=42))
])


logistic_regression_pipeline.fit(X_train, y_train)


y_pred_logistic = logistic_regression_pipeline.predict(X_test)

print('Logistic Regression Evaluation:')
print(classification_report(y_test, y_pred_logistic, target_names=['Flop', 'Average', 'Hit']))
print(f'Accuracy: {accuracy_score(y_test, y_pred_logistic)}')
conf_matrix_lr = confusion_matrix(y_test, y_pred_logistic, labels=['Flop', 'Average', 'Hit'])
print(conf_matrix_lr)


plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix_lr, annot=True, fmt="d", cmap='Blues', xticklabels=['Flop', 'Average', 'Hit'], yticklabels=['Flop', 'Average', 'Hit'])
plt.title('Confusion Matrix for Logistic Regression')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()


y_pred_prob_lr = logistic_regression_pipeline.predict_proba(X_test)
prob_df_lr = pd.DataFrame(y_pred_prob_lr, columns=logistic_regression_pipeline.named_steps['classifier'].classes_)
prob_df_melted_lr = prob_df_lr.melt(var_name='Class', value_name='Probability')

plt.figure(figsize=(12, 6))
sns.violinplot(x='Class', y='Probability', data=prob_df_melted_lr)
plt.title('Distribution of Predicted Probabilities by Class for Logistic Regression')
plt.xlabel('Class')
plt.ylabel('Predicted Probability')
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'logistic_regression_classifier.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(logistic_regression_pipeline, file)

"""## KNN Neighbours Classifier"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import label_binarize
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import average_precision_score


knn_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', KNeighborsClassifier(n_neighbors=5))
])


knn_pipeline.fit(X_train, y_train)


y_pred_knn = knn_pipeline.predict(X_test)

print('K-Nearest Neighbors Evaluation:')
print(classification_report(y_test, y_pred_knn, target_names=['Flop', 'Average', 'Hit']))
print(f'Accuracy: {accuracy_score(y_test, y_pred_knn)}')
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn, labels=['Flop', 'Average', 'Hit'])
print(conf_matrix_knn)


plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix_knn, annot=True, fmt="d", cmap='Blues', xticklabels=['Flop', 'Average', 'Hit'], yticklabels=['Flop', 'Average', 'Hit'])
plt.title('Confusion Matrix for K-Nearest Neighbors')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(data=pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_knn}), x='Actual', hue='Predicted', multiple="dodge", shrink=.8)
plt.title('Predicted vs. Actual Class Counts for K-Nearest Neighbors')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()


df_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_knn})


class_distribution_actual = df_comparison['Actual'].value_counts().sort_index()
class_distribution_predicted = df_comparison['Predicted'].value_counts().sort_index()


df_plot = pd.DataFrame({'Actual': class_distribution_actual, 'Predicted': class_distribution_predicted})


df_plot.plot(kind='bar', figsize=(10, 6))
plt.title('Actual vs. Predicted Class Distribution')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', linewidth=0.7)
plt.legend(loc='best')
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'KNN_classifier.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(knn_pipeline, file)

"""## Single Vector Classifier"""

from sklearn.svm import SVC


svm_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', SVC(random_state=42))
])


svm_pipeline.fit(X_train, y_train)


y_pred_svm = svm_pipeline.predict(X_test)

print('Support Vector Machine Evaluation:')
print(classification_report(y_test, y_pred_svm, target_names=['Flop', 'Average', 'Hit']))
print(f'Accuracy: {accuracy_score(y_test, y_pred_svm)}')
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm, labels=['Flop', 'Average', 'Hit'])
print(conf_matrix_svm)


plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix_svm, annot=True, fmt="d", cmap='Blues', xticklabels=['Flop', 'Average', 'Hit'], yticklabels=['Flop', 'Average', 'Hit'])
plt.title('Confusion Matrix for Support Vector Machine')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

X_test_vis = pd.DataFrame(X_test).copy()
X_test_vis['ActualClass'] = y_test
X_test_vis['PredictedClass'] = y_pred_svm


plt.figure(figsize=(14, 7))


plt.subplot(1, 2, 1)
sns.boxplot(x='ActualClass', y='VOTES', data=X_test_vis)
plt.title('Box Plot of VOTES by Actual Class')


plt.subplot(1, 2, 2)
sns.boxplot(x='PredictedClass', y='VOTES', data=X_test_vis)
plt.title('Box Plot of VOTES by Predicted Class')

plt.tight_layout()
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'Single_vector_classifier.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(svm_pipeline, file)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns



X = df2.drop('RATING', axis=1)
y = df2['RATING']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


numeric_features = ['VOTES', 'RunTime','YEAR']
categorical_features = ['GENRE','ONE-LINE','STARS']


numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])


preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

"""## Linear Regression"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns


lr = Pipeline(steps=[('preprocessor', preprocessor),
                     ('regressor', LinearRegression())])

lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)


print("Mean Squared Error: ", mean_squared_error(y_test, y_pred))
print("R2 Score: ", r2_score(y_test, y_pred))
print("Mean Absolute Error: ", mean_absolute_error(y_test, y_pred))


plt.figure(figsize=(10,6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')
plt.show()


plt.figure(figsize=(10,6))
sns.distplot(y_test - y_pred)
plt.title('Distribution of Residuals')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'linear_regressor.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(lr, file)

"""## K Nearest Neighbours Regressor"""

from sklearn.neighbors import KNeighborsRegressor


knn = Pipeline(steps=[('preprocessor', preprocessor),
                      ('regressor', KNeighborsRegressor(n_neighbors=5))])

knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)


# Evaluation Metrics
print("Mean Squared Error: ", mean_squared_error(y_test, y_pred))
print("R2 Score: ", r2_score(y_test, y_pred))
print("Mean Absolute Error: ", mean_absolute_error(y_test, y_pred))

# Visualization - Actual vs. Predicted
plt.figure(figsize=(10,6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')
plt.show()

# Visualization - Residual Distribution
plt.figure(figsize=(10,6))
sns.distplot(y_test - y_pred)
plt.title('Distribution of Residuals')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'knn_regressor.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(knn, file)

"""## Single Vector Regressor"""

from sklearn.svm import SVR


svm_reg = Pipeline(steps=[('preprocessor', preprocessor),
                          ('regressor', SVR(kernel='linear'))])

svm_reg.fit(X_train, y_train)
y_pred = svm_reg.predict(X_test)


print("Mean Squared Error: ", mean_squared_error(y_test, y_pred))
print("R2 Score: ", r2_score(y_test, y_pred))
print("Mean Absolute Error: ", mean_absolute_error(y_test, y_pred))

# Visualization - Actual vs. Predicted
plt.figure(figsize=(10,6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')
plt.show()

# Visualization - Residual Distribution
plt.figure(figsize=(10,6))
sns.distplot(y_test - y_pred)
plt.title('Distribution of Residuals')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'svm_regressor.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(svm_reg, file)

"""## Random Forest Regressor"""

from sklearn.ensemble import RandomForestRegressor


rf = Pipeline(steps=[('preprocessor', preprocessor),
                     ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])

rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

# Evaluation Metrics
print("Random Forest Regressor")
print("Mean Squared Error: ", mean_squared_error(y_test, y_pred))
print("R2 Score: ", r2_score(y_test, y_pred))
print("Mean Absolute Error: ", mean_absolute_error(y_test, y_pred))

# Visualization - Actual vs. Predicted
plt.figure(figsize=(10,6))
plt.scatter(y_test, y_pred, alpha=0.3)
plt.xlabel('Actual Ratings')
plt.ylabel('Predicted Ratings')
plt.title('Random Forest Regressor: Actual vs Predicted Ratings')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'random_forest_regressor.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(rf, file)

"""## Gradient Boosting Regressor"""

from sklearn.ensemble import GradientBoostingRegressor


gb = Pipeline(steps=[('preprocessor', preprocessor),
                     ('regressor', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,
                                                             max_depth=3, random_state=42))])

gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)

# Evaluation Metrics
print("Gradient Boosting Regressor")
print("Mean Squared Error: ", mean_squared_error(y_test, y_pred))
print("R2 Score: ", r2_score(y_test, y_pred))
print("Mean Absolute Error: ", mean_absolute_error(y_test, y_pred))

# Visualization - Actual vs. Predicted
plt.figure(figsize=(10,6))
plt.scatter(y_test, y_pred, alpha=0.3)
plt.xlabel('Actual Ratings')
plt.ylabel('Predicted Ratings')
plt.title('Gradient Boosting Regressor: Actual vs Predicted Ratings')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)
plt.show()

import pickle

# Specify the path and file name to save the model
model_file_path = 'gradient_booster_regressor.pkl'

# Open a file in write-binary mode
with open(model_file_path, 'wb') as file:
    # Dump the rf_classifier_pipeline into the file
    pickle.dump(gb, file)

